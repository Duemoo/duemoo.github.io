---
layout: about
title: About
menu: true
order: 10
---

<br />

<img style="float: left;" src="{{ site.baseurl }}/assets/img/myimg.jpg" width="200" height="200">

<br />

<br />

<br />

<br />

<br />

# Hoyeon Chang 

Pronunciation: [hojʌn tɕɑŋ]



##### *Ph.D. Student*

###### *Graduate School of AI, KAIST*

[[Google Scholar]](https://scholar.google.com/citations?hl=en&user=jD4MD7sAAAAJ)

<br />

I am a second-year Ph.D. student in [Language & Knowledge Lab](https://lklab.kaist.ac.kr/) at KAIST Graduate School of AI. I am fortunate to be advised by [Minjoon Seo](https://seominjoon.github.io/). Before KAIST, I obtained a B.S. in Electrical & Computer Engineering and Biological Sciences at Seoul National University.

<!--My research interests lie in natural language processing and neuro-symbolic AI. My focus lies in exploring how knowledge representations can be encoded, transferred, and utilized for inference and reasoning in AI models. I believe that gaining such insights can pave the way toward building more safe and reliable AI systems.-->

<!--My academic pursuit centers on understanding how intelligent systems acquire and process knowledge from intricate patterns. My recent focus is to understand the  the analysis of language models, aiming to uncover the methods through which knowledge representations are encoded, transferred, and leveraged for inference and reasoning within AI frameworks. Passionately, I engage in blending concepts from a diverse array of disciplines related to my academic goals, including computational neuroscience, philosophy, linguistics, and psychology, to cultivate a comprehensive understanding of artificial intelligence.-->My academic goal is to understand how intelligent systems acquire and process knowledge from complex patterns, and develop systems that could perform robust variable binding and compositional reasoning. Specifically, my recent focus lies in analyzing language models to understand how they represent and utilize compositional knowledge. I am open and passionate about studying and integrating concepts from other fields involved in studying intelligence and knowledge (computational neuroscience, complex systems, philosophy, linguistics, psychology, etc.) to deepen my understanding of intelligent systems.

You can contact me via e-mail: [retapurayo@kaist.ac.kr](mailto:retapurayo@kaist.ac.kr)

<br />

---

## Education

<br />

- **Korea Advanced Institute of Science and Technology,  Feb 2024 - Present**

  Ph.D. in Artificial Intelligence

- **Korea Advanced Institute of Science and Technology,  Sep 2022 - Feb 2024**

  M.S. in Artificial Intelligence

- **Seoul National University, Mar 2018 - Aug 2022**

  B.S. in Biological Sciences and Electrical & Computer Engineering, *Summa cum laude*

- **Korea Science Academy of KAIST, Mar 2015 - Feb 2018**

<br />

---

## Research Experience

<br />

- **Research Intern at KAIST [LK Lab](https://lklab.kaist.ac.kr/), Feb 2022 - Aug 2022 (Advisor: [Minjoon Seo](https://seominjoon.github.io/))**

- **Research Intern at SNU [LDI Lab](https://seungwonh.github.io/ldi.html), Sep 2021 - Jan 2022 (Advisor: [Seungwon Hwang](https://seungwonh.github.io/))**

- **Research Intern at SNU [CHANGlab](https://qbio.io/), Dec 2020 - Feb 2021 (Advisor: [Hyeshik Chang](https://qbio.io/team/hyeshik-chang))**

- **SNU Undergraduate Research Program, May 2020 - Dec 2020 (Advisor: [Young-Jae Seok](https://biosci.snu.ac.kr/lomp/professor))**

<br />

---

## Publications

<br />

### 2025

- [**The Coverage Principle: A Framework for Understanding Compositional Generalization**](https://arxiv.org/abs/2505.20278), *ArXiv Preprint* 

  **Hoyeon Chang**\*, Jinho Park\*, Hanseul Cho, Sohee Yang, Miyoung Ko, Hyeonbin Hwang, Seungpil Won, Dohaeng Lee, Youbin Ahn, Minjoon Seo
  
- [**Let's Predict Sentence by Sentence**](https://arxiv.org/abs/2505.22202), *ArXiv Preprint* 

  Hyeonbin Hwang\*, Byeongguk Jeon\*, Seungone Kim, Jiyeon Kim, **Hoyeon Chang**, Sohee Yang, Seungpil Won, Dohaeng Lee, Youbin Ahn, Minjoon Seo
  
- [**How Does Vision-Language Adaptation Impact the Safety of Vision Language Models?**](https://arxiv.org/abs/2410.07571), *ICLR 2025*

  Seongyun Lee\*, Geewook Kim\*, Jiyeon Kim\*, Hyunji Lee, **Hoyeon Chang**, Sue Hyun Park, and Minjoon Seo

### **2024**

- **[How Do Large Language Models Acquire Factual Knowledge During Pretraining?](https://arxiv.org/abs/2406.11813)**, *NeurIPS 2024*

  **Hoyeon Chang**, Jinho Park, Seonghyeon Ye, Sohee Yang, Youngkyung Seo, Du-Seong Chang, Minjoon Seo

### **2023**

- **[Nonparametric Decoding for Generative Retrieval](https://arxiv.org/abs/2210.02068)**, *ACL 2023 Findings*

  Hyunji Lee, Jaeyoung Kim, **Hoyeon Chang**, Hanseok Oh, Sohee Yang, Vlad Karpukhin, Yi Lu, Minjoon Seo

  

<br />

---

## Academic Leadership & Services

<br />

- **TMI (Thinking, Meaning, Intelligence) Group, Founder, Jul 2024 -  Present**

  Founded and leading a monthly interdisciplinary academic group inspired by Norbert Wiener’s project on cybernetics, bringing together graduate students from philosophy, neuroscience, linguistics, computer science, physics, and education. The group explores fundamental questions about thinking, meaning, and intelligence through collaborative discussions and projects

  

<br />

---

## Teaching

<br />

- Teaching Assistant, Large Language Models, KAIST, Fall 2023
- Teaching Assistant, Machine Learning Theory, KAIST, Spring 2023
  

<br />

---

## Invited Talks

<br />

- **How do Language Models Acquire and Utilize Factual Knowledge?** at NAVER Labs, Feb 2024
- **How do Language Models Acquire and Utilize Factual Knowledge?** at NAVER CLOVA, May 2024

<br />

---

## Awards

<br />

- **Best Poster Award, 1st International NLP Workshop at KAIST, 2024**
- **SNU Undergraduate Research Program Outstanding Research Award, 2021**
- **Hyoungae Scholarship, 2019 - 2021**
- **Zayed Future Energy Prize in global high schools(Asia) category, 2016**

<br />

---

## Languages

<br />

- **Native in Korean**
- **Fluent in English(TOEIC 925/990) and Japanese(JLPT N1 164/180)**
- **Beginner in German and Spanish**

<br />
